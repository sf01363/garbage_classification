
import streamlit as st
import torch
import torch.nn as nn

from PIL import Image, ImageOps
import numpy as np
import requests
from io import BytesIO
import requests
from torchvision import transforms


# ëª¨ë¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
model_url = 'https://github.com/sf01363/garbage_classification/raw/main/model.pth'
response = requests.get(model_url)
model_path = 'model.pth'
with open(model_path, 'wb') as f:
    f.write(response.content)

class CustomEfficientNet(nn.Module):
    def __init__(self, num_classes):
        super(CustomEfficientNet, self).__init__()

        # ì‚¬ì „ í•™ìŠµëœ EfficientNet ëª¨ë¸ ë¡œë“œ
        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')

        # ê¸°ì¡´ ë¶„ë¥˜ê¸° ë ˆì´ì–´ì˜ íŠ¹ì§• ìˆ˜ ê°€ì ¸ì˜¤ê¸°
        num_features = self.efficientnet._fc.in_features

        # ì»¤ìŠ¤í…€ ë¶„ë¥˜ê¸° ì •ì˜
        self.efficientnet._fc = nn.Sequential(
            nn.Linear(num_features, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        return self.efficientnet(x)

device = 'cpu'
model = torch.load(model_path, map_location="cpu")

# ëª¨ë¸ì˜ ìƒíƒœ ì‚¬ì „ ì—…ë°ì´íŠ¸
model.eval()

# í´ë˜ìŠ¤ ë ˆì´ë¸” ë”•ì…”ë„ˆë¦¬
class_labels = {
    0: 'ê³¨íŒì§€',
    1: 'ìœ ë¦¬',
    2: 'ê¸ˆì†/ìº”',
    3: 'ì¢…ì´',
    4: 'í”Œë¼ìŠ¤í‹±',
}

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# ì›¹í˜ì´ì§€ ì œëª©ê³¼ ì„¤ëª… ì¶”ê°€
st.set_page_config(page_title="ì¬í™œìš©í’ˆ ë¶„ë¦¬ ë°°ì¶œ", page_icon="â™»ï¸", layout="wide")
st.title("â™»ï¸ ì¬í™œìš©í’ˆ ë¶„ë¦¬ ë°°ì¶œ")
st.write("""
    ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì¬í™œìš© ê°€ëŠ¥í•œ ì“°ë ˆê¸° ì¢…ë¥˜ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  ì˜ˆì¸¡ í™•ë¥  ì„ê³„ê°’ì„ ì¡°ì •í•˜ì—¬ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.
""")

# ì‚¬ì´ë“œë°”ì— ì„¤ëª… ì¶”ê°€
st.markdown("""
    <style>
        [data-testid=stSidebar] {
            background-color: #3CB371;
        }
    </style>
    """, unsafe_allow_html=True)

st.sidebar.header("ì‚¬ìš© ë°©ë²•")
st.sidebar.write("""
    1. ì¬í™œìš© ì“°ë ˆê¸° ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (jpg, png, jpeg).
    2. ì˜ˆì¸¡ í™•ë¥  ì„ê³„ê°’ì„ ìŠ¬ë¼ì´ë”ë¥¼ í†µí•´ ì¡°ì •í•˜ì„¸ìš”.
    3. ì˜ˆì¸¡ ê²°ê³¼ì™€ í™•ë¥ ì„ í™•ì¸í•˜ì„¸ìš”.
""")

# ì¬í™œìš© ë°©ë²•ê³¼ ì„¤ëª…ì„ ì •ì˜í•œ ì‚¬ì „
recycle_methods = {
    "í”Œë¼ìŠ¤í‹±": 'ğŸ§´ ëª¨ë“  í”Œë¼ìŠ¤í‹±ì€ ê¹”ë”í•˜ê²Œ í—¹ê¶ˆ ì¤˜. ğŸ§½ğŸ’¦ í”Œë¼ìŠ¤í‹±ì´ "ë‚˜ë„ ê¹”ë”í•œ ê²Œ ì¢‹ì•„!"ë¼ê³  ë§í•˜ê³  ìˆì–´. ë¼ë²¨ë„ ê¼­ ë–¼ ì¤˜ì•¼ í•´! ğŸ˜„ğŸ’• í”Œë¼ìŠ¤í‹±ì´ "ë‚´ ë¼ë²¨ì€ í•„ìš” ì—†ì–´!"ë¼ê³  ìë‘ìŠ¤ëŸ¬ì›Œí•´.',  # í”Œë¼ìŠ¤í‹±ì— ëŒ€í•œ ì„¤ëª…
    "ì¢…ì´": 'ğŸ“„ ê¸°ë¦„ì´ë‚˜ ìŒì‹ë¬¼ ì–¼ë£© ì—†ëŠ” ì¢…ì´ë§Œ ì¬í™œìš©í•  ìˆ˜ ìˆì–´. ğŸ§¼ ì¢…ì´ê°€ "ë‚˜ëŠ” ê¸°ë¦„ê¸°ê°€ ì‹«ì–´!" í•˜ê³  ì™¸ì¹˜ëŠ” ì†Œë¦¬ê°€ ë“¤ë¦¬ì§€ ì•Šë‹ˆ? ìŠ¤í…Œì´í”Œê³¼ í´ë¦½ì€ ë¯¸ë¦¬ ë¹¼ ì¤˜! âœ‚ï¸âœ¨ ì¢…ì´ê°€ "ììœ ë¥¼ ë‹¬ë¼!"ê³  ì™¸ì¹˜ê³  ìˆì–´!',  # ì¢…ì´ì— ëŒ€í•œ ì„¤ëª…
    "ê¸ˆì†/ìº”": 'ğŸ¥« ìº”ì€ ë°˜ì§ë°˜ì§ ê¹¨ë—í•˜ê²Œ í—¹ê¶ˆì„œ ë²„ë ¤ ì¤˜. ğŸ§½ğŸ’¦ ìº”ë„ ìƒ¤ì›Œë¥¼ ì¢‹ì•„í•œë‹¨ë‹¤! ë¼ë²¨ì€ ê¼­ ë–¼ ì¤˜ì•¼ í•´. ğŸ˜Š ìº”ì€ "ë‚´ ë¼ë²¨ì€ ë‚˜ì˜ ìì¡´ì‹¬!"ì´ë¼ê³  ìƒê°í•˜ê³  ìˆì–´.',  # ê¸ˆì†/ìº”ì— ëŒ€í•œ ì„¤ëª…
    "ìœ ë¦¬": 'ğŸ¾ ìœ ë¦¬ë³‘ë„ ê¹¨ë—í•˜ê²Œ í—¹ê¶ˆì„œ ë²„ë ¤ ì¤˜. ğŸ§´ğŸ’§ ìœ ë¦¬ë³‘ì´ "ê¹¨ë—í•˜ê²Œ ë¶€íƒí•´!"ë¼ê³  ì†ì‚­ì´ëŠ” ê²ƒ ê°™ì§€ ì•Šë‹ˆ? ëšœê»‘ê³¼ ë§ˆê°œëŠ” ë¹¼ ì¤˜! ğŸ¥‚ ìœ ë¦¬ë³‘ì´ "ëšœê»‘ì€ ë‚˜ì˜ ëª¨ìì•¼!"ë¼ê³  ìƒê°í•´.',  # ìœ ë¦¬ì— ëŒ€í•œ ì„¤ëª…
    "ê³¨íŒì§€": 'ğŸ“¦ ëª¨ë“  í…Œì´í”„ë‘ ìŠ¤í‹°ì»¤ëŠ” ì‹¹ì‹¹ ì œê±°í•´ ì¤˜! âœ‚ï¸ ì•„ë‹ˆ, ê³¨íŒì§€ê°€ íŒ¨ì…˜ì‡¼ì— ë‚˜ê°€ëŠ” ê±´ ì•„ë‹ˆì§€ë§Œ ê¹”ë”í•˜ê²Œ í•´ì£¼ë©´ ë” ì¢‹ì•„í•´. ğŸ˜„ ê·¸ë¦¬ê³  ì –ì§€ ì•Šê²Œ ì˜ ë³´ê´€í•´ ì¤˜. â˜”ï¸ ê³¨íŒì§€ì˜ ì²œì ì€ ë¬¼ì´ì•¼!'  # ê³¨íŒì§€ì— ëŒ€í•œ ì„¤ëª…
}

# ë“œë¡­ë‹¤ìš´ ë©”ë‰´ë¥¼ ìƒì„±í•˜ì—¬ ì„ íƒí•œ ì¬í™œìš© ë°©ë²•ì— ëŒ€í•œ ì„¤ëª…ì„ í‘œì‹œ
selected_method = st.sidebar.selectbox("ì¬í™œìš© ë°©ë²•", list(recycle_methods.keys()))
if selected_method:
    st.sidebar.write(recycle_methods[selected_method])


# ì—¬ê¸°ì„œë¶€í„°ëŠ” ì´ë¯¸ì§€
file = st.file_uploader('ì´ë¯¸ì§€ë¥¼ ì˜¬ë ¤ì£¼ì„¸ìš”', type=['jpg', 'png'])

if file is None:
    st.text('ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ì˜¬ë ¤ì£¼ì„¸ìš”.')
else:
    image = Image.open(file).convert('RGB')
    st.image(image, caption='Uploaded Image.', use_column_width=True, width=0.8)
    
    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    image = transform(image).unsqueeze(0).to(device)
    
    # ëª¨ë¸ ì˜ˆì¸¡
    with torch.no_grad():
        outputs = model(image)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)
        _, predicted = torch.max(outputs, 1)

    # ì˜ˆì¸¡ í™•ë¥  ìŠ¬ë¼ì´ë” ì¶”ê°€
    threshold = st.slider('ì˜ˆì¸¡ í™•ë¥  ì„ê³„ê°’ì„ ì„ íƒí•˜ì„¸ìš”', 0.0, 1.0, 0.5, 0.01)

    # ì˜ˆì¸¡ ê²°ê³¼ ì²˜ë¦¬
    pred_class = class_labels[predicted.item()]
    pred_probability = probabilities[0, predicted.item()].item()
    
    # ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ì— ë”°ë¼ í•´ë‹¹ í´ë˜ìŠ¤ì˜ ë°°ì¶œ ë°©ë²•ì„ í‘œì‹œ
    if pred_probability >= threshold:
        st.success(f'ë¶„ë¥˜ ê²°ê³¼ : í•´ë‹¹ ì¬í™œìš©í’ˆì´ "{pred_class}"ì¼ í™•ë¥ ì€ {pred_probability:.2f}ì…ë‹ˆë‹¤.')
        if pred_class in recycle_methods:
            st.write(recycle_methods[pred_class])
        else:
            st.warning("í•´ë‹¹í•˜ëŠ” ë°°ì¶œ ë°©ë²•ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.warning(f'ë¶„ë¥˜ ê²°ê³¼ : ì¼ë°˜ ì“°ë ˆê¸°ì¼ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤.')
