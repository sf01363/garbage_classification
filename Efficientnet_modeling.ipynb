{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sf01363/garbage_classification/blob/main/Efficientnet_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch_size = 16\n",
        "\n",
        "train Loss: 0.0506 Acc: 0.9881\n",
        "val Loss: 0.2090 Acc: 0.9331\n",
        "Best val Acc: 0.945607\n",
        "Test Acc: 0.9393\n",
        "\n",
        "----------\n",
        "combine\n",
        "train Loss: 0.0531 Acc: 0.9854\n",
        "val Loss: 0.1945 Acc: 0.9456\n",
        "Best val Acc: 0.956067\n",
        "Test Acc: 0.7301"
      ],
      "metadata": {
        "id": "DnXULhBGeble"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a58u8dD7dZe3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\n",
        "\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import scipy\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import ImageFolder\n",
        "import pdb\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "3FLXCVvqv1UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "if tf.test.gpu_device_name():\n",
        "    print(f\"GPU is available: {tf.test.gpu_device_name()}\")\n",
        "else:\n",
        "    print(\"GPU is not available.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGLXtQLev1Rg",
        "outputId": "5e53cfd2-284d-4fb9-d25c-dddf0af4110a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PizaaRiaaa/garbage-classification.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aZ-U041S93Y",
        "outputId": "0417446a-5d9c-4c41-8999-1c62aa442f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'garbage-classification'...\n",
            "remote: Enumerating objects: 5148, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 5148 (delta 41), reused 49 (delta 17), pack-reused 5072\u001b[K\n",
            "Receiving objects: 100% (5148/5148), 44.22 MiB | 11.78 MiB/s, done.\n",
            "Resolving deltas: 100% (2181/2181), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "\n",
        "# 경로 설정\n",
        "imagepath_cardboard = r\"garbage-classification/Garbage/original_images/cardboard\"\n",
        "imagepath_glass = r\"garbage-classification/Garbage/original_images/glass\"\n",
        "imagepath_metal = r\"garbage-classification/Garbage/original_images/metal\"\n",
        "imagepath_paper = r\"garbage-classification/Garbage/original_images/paper\"\n",
        "imagepath_plastic = r\"garbage-classification/Garbage/original_images/plastic\"\n",
        "imagepath_trash = r\"garbage-classification/Garbage/original_images/trash\""
      ],
      "metadata": {
        "id": "GXDBHQTMTQ0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 데이터셋 로드\n",
        "data_dir = 'garbage-classification/Garbage/original_images'\n",
        "dataset = datasets.ImageFolder(data_dir, transform=transform)\n"
      ],
      "metadata": {
        "id": "y4vOoDLBA16b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trash 데이터셋 로드 및 필터링\n",
        "trash_indices = [i for i, (path, _) in enumerate(dataset.imgs) if 'trash' in path] # 클래스가 trash인 데이터의 인덱스\n",
        "non_trash_indices = [i for i in range(len(dataset)) if i not in trash_indices] # 클래스가 trash가 아닌 데이터의 인덱스\n",
        "\n",
        "trash_dataset = Subset(dataset, trash_indices)\n",
        "non_trash_dataset = Subset(dataset, non_trash_indices)"
      ],
      "metadata": {
        "id": "74ViCMiiTWLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 랜덤 시드 고정\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "U69-hvzoVmVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# non_trash 데이터를 train, val, test로 분할\n",
        "train_size = int(0.6 * len(non_trash_dataset))\n",
        "val_size = int(0.2 * len(non_trash_dataset))\n",
        "test_size = len(non_trash_dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, non_trash_test_dataset = random_split(non_trash_dataset, [train_size, val_size, test_size])"
      ],
      "metadata": {
        "id": "ksXiLnOPRlOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # non_trash 데이터를 train, val, test로 분할\n",
        "# train_size = int(0.6 * len(non_trash_dataset))\n",
        "# val_size = int(0.2 * len(non_trash_dataset))\n",
        "# test_size = len(non_trash_dataset) - train_size - val_size\n",
        "\n",
        "# train_dataset, val_dataset, non_trash_test_dataset = random_split(non_trash_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "# #테스트 데이터셋; non_trash_test_dataset + trash_dataset\n",
        "# test_dataset = torch.utils.data.ConcatDataset([non_trash_test_dataset, trash_dataset])\n"
      ],
      "metadata": {
        "id": "mKjTENsmcCDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로더 설정\n",
        "\n",
        "batch_size = 16\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(non_trash_test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "DSwHXlgPV9vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 데이터 로더 설정\n",
        "\n",
        "# batch_size = 16\n",
        "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "2dnnkoKXcOSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DeiTConfig, DeiTForImageClassification"
      ],
      "metadata": {
        "id": "8JbvVgouYDBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DeiT 모델 구조 관련 하이퍼파라미터\n",
        "* Embedding Dimension (D): 입력 이미지 패치를 임베딩 벡터로 변환할 때의 차원 수입니다. 일반적으로 192, 384, 768 등으로 설정됩니다.\n",
        "예: dim=384\n",
        "* Patch Size (P): 입력 이미지를 나눌 패치의 크기입니다. 일반적으로 16x16, 32x32 등으로 설정됩니다.\n",
        "예: patch_size=16\n",
        "* Number of Layers (L): Transformer 블록의 층 수입니다. 모델의 깊이를 나타내며, 일반적으로 12, 24, 32 등으로 설정됩니다.\n",
        "예: depth=12\n",
        "* Number of Heads (H): Multi-head Self-Attention에서의 헤드 수입니다. 일반적으로 3, 6, 12 등으로 설정됩니다.\n",
        "예: num_heads=6\n",
        "* MLP Dimension (FFN): Transformer 블록 내의 Feed Forward Network(FFN)의 내부 차원입니다. 일반적으로 임베딩 차원의 2-4배로 설정됩니다.\n",
        "예: mlp_dim=1536\n",
        "* Dropout Rate: 드롭아웃 비율로, 과적합을 방지하기 위해 사용됩니다.\n",
        "예: dropout=0.1\n",
        "## 학습 관련 하이퍼파라미터\n",
        "* Learning Rate (LR): 학습 속도를 조절하는 하이퍼파라미터로, 모델이 최적의 가중치를 찾는 속도에 영향을 미칩니다.\n",
        "예: learning_rate=3e-4\n",
        "* Batch Size: 한 번의 역전파에서 사용할 샘플 수입니다. 모델 학습의 효율성과 성능에 영향을 미칩니다.\n",
        "예: batch_size=64\n",
        "* Weight Decay: L2 정규화 항으로, 과적합을 방지하기 위해 사용됩니다.\n",
        "예: weight_decay=0.05\n",
        "* Number of Epochs: 전체 데이터셋을 몇 번 반복할지 결정하는 값입니다.\n",
        "예: epochs=100\n",
        "* Optimizer: 모델을 업데이트하는 데 사용되는 최적화 알고리즘입니다. AdamW가 일반적으로 사용됩니다.\n",
        "예: optimizer=AdamW\n",
        "* Warmup Steps: 학습 초기에 학습률을 점진적으로 증가시키는 단계 수입니다.\n",
        "예: warmup_steps=5000\n",
        "\n",
        "## DeiTConfig:\n",
        "* image_size: 입력 이미지의 크기.\n",
        "* patch_size: 입력 이미지를 나눌 패치 크기.\n",
        "* num_channels: 입력 이미지의 채널 수 (일반적으로 RGB 이미지는 3).\n",
        "* hidden_size: 임베딩 벡터의 크기.\n",
        "* num_hidden_layers: Transformer 블록의 층 수.\n",
        "* num_attention_heads: Multi-head Self-Attention에서의 헤드 수.\n",
        "* intermediate_size: FFN의 내부 차원.\n",
        "* dropout_rate: 드롭아웃 비율.\n",
        "## Optimizer 및 Scheduler:\n",
        "* AdamW: Adam의 변형으로, L2 정규화 대신 가중치 감쇠를 사용하여 더 나은 정규화 효과를 제공합니다.\n",
        "* learning_rate=3e-4: 학습률.\n",
        "* weight_decay=0.05: L2 정규화 강도."
      ],
      "metadata": {
        "id": "hLzQOykNe4EW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K6zndUYJorZA",
        "outputId": "4045e3f7-7e5c-46c0-9669-f31db4dc5506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from efficientnet_pytorch) (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->efficientnet_pytorch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->efficientnet_pytorch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet_pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->efficientnet_pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16429 sha256=2fb7a34e7327a64771c42d3137d7d986cd0d0a057497d284654f2da1befa5422\n",
            "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "class CustomEfficientNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CustomEfficientNet, self).__init__()\n",
        "\n",
        "        # 사전 학습된 EfficientNet 모델 로드\n",
        "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "\n",
        "        # 기존 분류기 레이어의 특징 수 가져오기\n",
        "        num_features = self.efficientnet._fc.in_features\n",
        "\n",
        "        # 커스텀 분류기 정의\n",
        "        self.efficientnet._fc = nn.Sequential(\n",
        "            nn.Linear(num_features, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.efficientnet(x)\n"
      ],
      "metadata": {
        "id": "hoVxAMnjW_1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예제 사용법\n",
        "num_classes = 5 # non_trash\n",
        "model = CustomEfficientNet(num_classes=num_classes)\n",
        "\n",
        "# # 예제 사용법\n",
        "# num_classes = 6 # with trash\n",
        "# model = CustomEfficientNet(num_classes=num_classes)"
      ],
      "metadata": {
        "id": "rJxd8aYfcezG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move the model to the GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "\n",
        "# 옵티마이저 및 손실함수 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "# scheduler로 학습률 조정\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "# 모델 학습\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaQg-O1aYe4G",
        "outputId": "7d5e70f2-8d15-4998-9367-7d81a938c4aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomEfficientNet(\n",
              "  (efficientnet): EfficientNet(\n",
              "    (_conv_stem): Conv2dStaticSamePadding(\n",
              "      3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "      (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
              "    )\n",
              "    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "    (_blocks): ModuleList(\n",
              "      (0): MBConvBlock(\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
              "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (1): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
              "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (2): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
              "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (3): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
              "          (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (4): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
              "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (5): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
              "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (6-7): 2 x MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
              "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (8): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
              "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (9-10): 2 x MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
              "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (11): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
              "          (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (12-14): 3 x MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
              "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (15): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
              "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "    )\n",
              "    (_conv_head): Conv2dStaticSamePadding(\n",
              "      320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "      (static_padding): Identity()\n",
              "    )\n",
              "    (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "    (_dropout): Dropout(p=0.2, inplace=False)\n",
              "    (_fc): Sequential(\n",
              "      (0): Linear(in_features=1280, out_features=512, bias=True)\n",
              "      (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU()\n",
              "      (3): Dropout(p=0.5, inplace=False)\n",
              "      (4): Linear(in_features=512, out_features=256, bias=True)\n",
              "      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (6): ReLU()\n",
              "      (7): Dropout(p=0.5, inplace=False)\n",
              "      (8): Linear(in_features=256, out_features=6, bias=True)\n",
              "    )\n",
              "    (_swish): MemoryEfficientSwish()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 함수\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=20):\n",
        "    best_model_wts = model.state_dict()\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # 각 에포크마다 훈련 및 검증\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # 모델을 훈련 모드로 설정\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()  # 모델을 검증 모드로 설정\n",
        "                dataloader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # 데이터 반복\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader.dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # 모델을 깊은 복사(deep copy) 함\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = model.state_dict()\n",
        "\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # 최적의 모델 가중치 로드\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "yR5fDF_6REEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "model = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=25)"
      ],
      "metadata": {
        "id": "JZ6ZNSy0RECs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a8a67c-05b8-4b3e-ba4e-2a8f5f0dc97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 1.5952 Acc: 0.3808\n",
            "val Loss: 1.0842 Acc: 0.7301\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.9876 Acc: 0.6771\n",
            "val Loss: 0.6476 Acc: 0.8431\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.6724 Acc: 0.7978\n",
            "val Loss: 0.4621 Acc: 0.8912\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.4855 Acc: 0.8724\n",
            "val Loss: 0.3782 Acc: 0.9142\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.3710 Acc: 0.8933\n",
            "val Loss: 0.3110 Acc: 0.9226\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.2939 Acc: 0.9331\n",
            "val Loss: 0.2751 Acc: 0.9247\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.2388 Acc: 0.9484\n",
            "val Loss: 0.2532 Acc: 0.9351\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.1962 Acc: 0.9561\n",
            "val Loss: 0.2471 Acc: 0.9393\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.1653 Acc: 0.9665\n",
            "val Loss: 0.2320 Acc: 0.9372\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.1426 Acc: 0.9714\n",
            "val Loss: 0.2387 Acc: 0.9331\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.1452 Acc: 0.9686\n",
            "val Loss: 0.2267 Acc: 0.9331\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.1221 Acc: 0.9749\n",
            "val Loss: 0.2058 Acc: 0.9351\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.1031 Acc: 0.9833\n",
            "val Loss: 0.2163 Acc: 0.9351\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.0916 Acc: 0.9798\n",
            "val Loss: 0.2163 Acc: 0.9435\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.0903 Acc: 0.9791\n",
            "val Loss: 0.2192 Acc: 0.9289\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.0907 Acc: 0.9763\n",
            "val Loss: 0.2095 Acc: 0.9414\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.0767 Acc: 0.9812\n",
            "val Loss: 0.2011 Acc: 0.9456\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.0931 Acc: 0.9714\n",
            "val Loss: 0.2100 Acc: 0.9331\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.0778 Acc: 0.9826\n",
            "val Loss: 0.1852 Acc: 0.9414\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.0740 Acc: 0.9847\n",
            "val Loss: 0.2128 Acc: 0.9435\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.0755 Acc: 0.9874\n",
            "val Loss: 0.1921 Acc: 0.9498\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.0544 Acc: 0.9902\n",
            "val Loss: 0.1777 Acc: 0.9561\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.0686 Acc: 0.9819\n",
            "val Loss: 0.1753 Acc: 0.9519\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.0541 Acc: 0.9861\n",
            "val Loss: 0.1877 Acc: 0.9477\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.0531 Acc: 0.9854\n",
            "val Loss: 0.1945 Acc: 0.9456\n",
            "Best val Acc: 0.956067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 함수\n",
        "def test_model(model, test_loader):\n",
        "    model.eval()\n",
        "    running_corrects = 0\n",
        "\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    test_acc = running_corrects.double() / len(test_loader.dataset)\n",
        "    print(f'Test Acc: {test_acc:.4f}')"
      ],
      "metadata": {
        "id": "JcKoC9KmaAq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 테스트\n",
        "test_model(model, test_loader)"
      ],
      "metadata": {
        "id": "CUtc60WERECL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "619c0b64-853b-4185-d969-ffc2d688249d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc: 0.7301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 저장"
      ],
      "metadata": {
        "id": "ebbSZyeOwB6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습 후 저장하기\n",
        "torch.save(model, 'model.pth')\n",
        "\n",
        "# 저장된 모델 불러오기\n",
        "#model = torch.load('model.pth')\n",
        "#model = model.to(device)\n",
        "\n",
        "# # 모델 학습 후 저장하기\n",
        "# torch.save(model, 'model_combine.pth')\n",
        "\n",
        "# # 저장된 모델 불러오기\n",
        "# model = torch.load('model_combine.pth')\n",
        "# model = model.to(device)"
      ],
      "metadata": {
        "id": "hZ2EoQNYREBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 일반쓰레기 분류 정도 확인"
      ],
      "metadata": {
        "id": "HRywvyglwaqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trash_dataset = Subset(dataset, trash_indices)\n",
        "trash_loader = DataLoader(trash_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "iVQ7jDrEwBbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 함수\n",
        "def test_model_(model, test_loader):\n",
        "    model.eval()\n",
        "    running_corrects = 0\n",
        "\n",
        "    # 전체 예측과 확률을 저장할 리스트\n",
        "    all_preds = []\n",
        "    all_probs = []\n",
        "    max_probs = []\n",
        "\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            probs = F.softmax(outputs, dim=1)  # 소프트맥스 함수로 확률값 계산\n",
        "\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # 예측과 확률 저장\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_probs.extend(probs.cpu().numpy())\n",
        "        max_probs.extend(torch.max(probs, dim=1)[0].cpu().numpy())\n",
        "\n",
        "\n",
        "    test_acc = running_corrects.double() / len(test_loader.dataset)\n",
        "    print(f'Test Acc: {test_acc:.4f}')\n",
        "\n",
        "    # 각 이미지에 대한 예측 결과와 확률을 데이터프레임으로 생성\n",
        "    df_data = {\n",
        "        'Image Index': list(range(1, len(all_preds) + 1)),\n",
        "        'Predicted Class': all_preds,\n",
        "        'Probabilities': [', '.join([f'{prob:.5f}' for prob in prob_list]) for prob_list in all_probs],\n",
        "         'Max Probability': [f'{prob:.5f}' for prob in max_probs]\n",
        "    }\n",
        "    df = pd.DataFrame(df_data)\n",
        "    return df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QGoTfBZcRDYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model_(model, trash_loader).head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "MpF2RWVp0swC",
        "outputId": "fe98e064-ccac-4b5c-b8b5-0de93be64f1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Image Index  Predicted Class                                Probabilities  \\\n",
              "0            1                4  0.00575, 0.00901, 0.00828, 0.00761, 0.96935   \n",
              "1            2                3  0.08132, 0.00323, 0.00717, 0.89928, 0.00900   \n",
              "2            3                2  0.00591, 0.00153, 0.97254, 0.01722, 0.00280   \n",
              "3            4                2  0.02707, 0.01653, 0.57396, 0.03002, 0.35243   \n",
              "4            5                2  0.00616, 0.00366, 0.68365, 0.02086, 0.28568   \n",
              "\n",
              "  Max Probability  \n",
              "0         0.96935  \n",
              "1         0.89928  \n",
              "2         0.97254  \n",
              "3         0.57396  \n",
              "4         0.68365  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1f3f16f-f211-4000-9241-6cc037ac74c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Index</th>\n",
              "      <th>Predicted Class</th>\n",
              "      <th>Probabilities</th>\n",
              "      <th>Max Probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.00575, 0.00901, 0.00828, 0.00761, 0.96935</td>\n",
              "      <td>0.96935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0.08132, 0.00323, 0.00717, 0.89928, 0.00900</td>\n",
              "      <td>0.89928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00591, 0.00153, 0.97254, 0.01722, 0.00280</td>\n",
              "      <td>0.97254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0.02707, 0.01653, 0.57396, 0.03002, 0.35243</td>\n",
              "      <td>0.57396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00616, 0.00366, 0.68365, 0.02086, 0.28568</td>\n",
              "      <td>0.68365</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1f3f16f-f211-4000-9241-6cc037ac74c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b1f3f16f-f211-4000-9241-6cc037ac74c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b1f3f16f-f211-4000-9241-6cc037ac74c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-72635f93-de1b-4ea4-be2a-d2188a0c64e2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-72635f93-de1b-4ea4-be2a-d2188a0c64e2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-72635f93-de1b-4ea4-be2a-d2188a0c64e2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"test_model_(model, trash_loader)\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Image Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted Class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 2,\n        \"max\": 4,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4,\n          3,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Probabilities\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"0.08132, 0.00323, 0.00717, 0.89928, 0.00900\",\n          \"0.00616, 0.00366, 0.68365, 0.02086, 0.28568\",\n          \"0.00591, 0.00153, 0.97254, 0.01722, 0.00280\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Max Probability\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"0.89928\",\n          \"0.68365\",\n          \"0.97254\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    }
  ]
}